
## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æœ€ç®€å•çš„ä½¿ç”¨

```python
from pose_transforms import build_train_pipeline

codec = {
    'input_size': (192, 256),
    'heatmap_size': (48, 64),
    'sigma': 2.0
}

pipeline = build_train_pipeline(codec)

results = {
    'img_path': 'image.jpg',
    'bbox': [100, 100, 200, 300],
    'keypoints': keypoints,  # (N, 2)
    'keypoints_visible': visible  # (N,)
}

for transform in pipeline:
    results = transform(results)
```

## ğŸ“Š æ•°æ®æ ¼å¼é€ŸæŸ¥

### è¾“å…¥æ ¼å¼
- `img_path`: å›¾åƒè·¯å¾„ (str)
- `bbox`: [x, y, w, h] (list/array)
- `keypoints`: (N, 2) numpy array
- `keypoints_visible`: (N,) numpy array, å€¼ä¸º0æˆ–1

### è¾“å‡ºæ ¼å¼
- `img`: (3, H, W) torch.Tensor, å½’ä¸€åŒ–åˆ°[0,1]
- `heatmaps`: (N, H', W') torch.Tensor
- `keypoint_weights`: (N,) torch.Tensor

## ğŸ¯ å¸¸ç”¨é…ç½®

### COCO 17å…³é”®ç‚¹

```python
flip_pairs = [
    (1, 2), (3, 4), (5, 6), (7, 8),
    (9, 10), (11, 12), (13, 14), (15, 16)
]

upper_body_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
lower_body_ids = [11, 12, 13, 14, 15, 16]
```

### æ ‡å‡†è¾“å…¥å°ºå¯¸

| æ¨¡å‹ç±»å‹ | input_size | heatmap_size | sigma |
|---------|------------|--------------|-------|
| è½»é‡çº§   | (128, 192) | (32, 48)     | 2.0   |
| æ ‡å‡†     | (192, 256) | (48, 64)     | 2.0   |
| é«˜ç²¾åº¦   | (256, 320) | (64, 80)     | 2.0   |

## ğŸ”§ Transformå‚æ•°

### RandomFlip
```python
RandomFlip(
    direction='horizontal',  # 'horizontal' æˆ– 'vertical'
    prob=0.5                # æ¦‚ç‡
)
```

### RandomHalfBody
```python
RandomHalfBody(
    min_total_keypoints=8,
    min_half_keypoints=2,
    prob=0.3
)
```

### RandomBBoxTransform
```python
RandomBBoxTransform(
    scale_factor=(0.75, 1.5),
    shift_factor=0.16,
    rotate_factor=40,
    prob=1.0
)
```

### TopdownAffine
```python
TopdownAffine(
    input_size=(192, 256)  # (W, H)
)
```

### GenerateTarget
```python
codec = {
    'input_size': (192, 256),
    'heatmap_size': (48, 64),
    'sigma': 2.0
}
GenerateTarget(encoder=codec)
```

## ğŸ’¡ å¸¸è§æ¨¡å¼

### è®­ç»ƒPipeline
```python
pipeline = [
    LoadImage(),
    GetBBoxCenterScale(),
    RandomFlip(prob=0.5),
    RandomHalfBody(prob=0.3),
    RandomBBoxTransform(),
    TopdownAffine(input_size),
    GenerateTarget(codec),
    PackPoseInputs()
]
```

### éªŒè¯Pipeline
```python
pipeline = [
    LoadImage(),
    GetBBoxCenterScale(),
    TopdownAffine(input_size),
    PackPoseInputs()
]
```

### æ¨ç†Pipelineï¼ˆæ— å…³é”®ç‚¹ï¼‰
```python
pipeline = [
    LoadImage(),
    GetBBoxCenterScale(),
    TopdownAffine(input_size),
    PackPoseInputs()
]
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: çƒ­å›¾å…¨æ˜¯0
**åŸå› **: å…³é”®ç‚¹åæ ‡è¶…å‡ºå›¾åƒèŒƒå›´æˆ–keypoints_visibleè®¾ç½®é”™è¯¯
**è§£å†³**: æ£€æŸ¥å…³é”®ç‚¹åæ ‡å’Œå¯è§æ€§æ ‡è®°

### é—®é¢˜2: ç¿»è½¬åå…³é”®ç‚¹é”™ä½
**åŸå› **: æœªæä¾›flip_pairsæˆ–é…ç½®é”™è¯¯
**è§£å†³**: ç¡®ä¿flip_pairsåŒ…å«æ‰€æœ‰å¯¹ç§°å…³é”®ç‚¹å¯¹

### é—®é¢˜3: ä»¿å°„å˜æ¢åå›¾åƒå˜å½¢
**åŸå› **: centerå’Œscaleè®¾ç½®ä¸æ­£ç¡®
**è§£å†³**: æ£€æŸ¥bboxæ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ä½¿ç”¨GetBBoxCenterScale

### é—®é¢˜4: å†…å­˜å ç”¨é«˜
**åŸå› **: batch_sizeè¿‡å¤§æˆ–çƒ­å›¾åˆ†è¾¨ç‡è¿‡é«˜
**è§£å†³**: å‡å°batch_sizeæˆ–é™ä½heatmap_size

## ğŸ“ ä»£ç ç‰‡æ®µ

### åˆ›å»ºDataset
```python
class MyDataset(Dataset):
    def __init__(self, data_list, pipeline):
        self.data_list = data_list
        self.pipeline = pipeline
    
    def __getitem__(self, idx):
        data = self.data_list[idx]
        results = {
            'img_path': data['img_path'],
            'bbox': data['bbox'],
            'keypoints': data['keypoints'],
            'keypoints_visible': data['keypoints_visible']
        }
        for transform in self.pipeline:
            results = transform(results)
        return results
```

### è‡ªå®šä¹‰Transform
```python
class MyTransform:
    def __init__(self, param1):
        self.param1 = param1
    
    def __call__(self, results):
        # å¤„ç†results
        return results
```

### è®­ç»ƒå¾ªç¯
```python
for epoch in range(num_epochs):
    for batch in dataloader:
        imgs = batch['img']
        heatmaps = batch['heatmaps']
        
        pred = model(imgs)
        loss = criterion(pred, heatmaps)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

## ğŸ”— ç›¸å…³èµ„æº

- GitHub: [é¡¹ç›®åœ°å€]
- æ–‡æ¡£: README.md
- ç¤ºä¾‹: examples.py
- æµ‹è¯•: test_transforms.py

