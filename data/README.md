# æ•°æ®å¢å¼º Pipeline - PyTorchå®ç°


## ğŸ“‹ åŠŸèƒ½ç‰¹æ€§

### å·²å®ç°çš„Transform

1. **LoadImage** - å›¾åƒåŠ è½½
   - æ”¯æŒä»æ–‡ä»¶è·¯å¾„åŠ è½½å›¾åƒ
   - è‡ªåŠ¨BGRåˆ°RGBè½¬æ¢
   - æ”¯æŒfloat32è½¬æ¢

2. **GetBBoxCenterScale** - è¾¹ç•Œæ¡†å¤„ç†
   - ä»bboxè®¡ç®—ä¸­å¿ƒç‚¹å’Œå°ºåº¦
   - æ”¯æŒ[x, y, w, h]å’Œ[x1, y1, x2, y2]æ ¼å¼
   - å¯é…ç½®paddingç³»æ•°

3. **RandomFlip** - éšæœºç¿»è½¬
   - æ”¯æŒæ°´å¹³/å‚ç›´ç¿»è½¬
   - è‡ªåŠ¨å¤„ç†å…³é”®ç‚¹åæ ‡ç¿»è½¬
   - æ”¯æŒå·¦å³å¯¹ç§°å…³é”®ç‚¹äº¤æ¢ï¼ˆé€šè¿‡flip_pairsï¼‰

4. **RandomHalfBody** - éšæœºåŠèº«å¢å¼º
   - éšæœºé€‰æ‹©ä¸ŠåŠèº«æˆ–ä¸‹åŠèº«
   - è‡ªåŠ¨è°ƒæ•´bboxé€‚åº”é€‰ä¸­åŒºåŸŸ
   - å¯é…ç½®æœ€å°å…³é”®ç‚¹æ•°é‡

5. **RandomBBoxTransform** - éšæœºè¾¹ç•Œæ¡†å˜æ¢
   - éšæœºç¼©æ”¾ï¼ˆscaleï¼‰
   - éšæœºå¹³ç§»ï¼ˆshiftï¼‰
   - éšæœºæ—‹è½¬ï¼ˆrotationï¼‰

6. **TopdownAffine** - ä»¿å°„å˜æ¢
   - å°†å›¾åƒå’Œå…³é”®ç‚¹å˜æ¢åˆ°å›ºå®šå°ºå¯¸
   - æ”¯æŒæ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»
   - ä½¿ç”¨ä»¿å°„å˜æ¢çŸ©é˜µ

7. **GenerateTarget** - ç”Ÿæˆè®­ç»ƒç›®æ ‡
   - ç”Ÿæˆé«˜æ–¯çƒ­å›¾ï¼ˆGaussian Heatmapï¼‰
   - å¯é…ç½®çƒ­å›¾å°ºå¯¸å’Œsigma
   - è‡ªåŠ¨å¤„ç†å…³é”®ç‚¹å¯è§æ€§

8. **PackPoseInputs** - æ‰“åŒ…è¾“å…¥
   - è½¬æ¢ä¸ºPyTorch Tensor
   - å›¾åƒå½’ä¸€åŒ–åˆ°[0, 1]
   - æ‰“åŒ…å…ƒä¿¡æ¯

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install torch numpy opencv-python pillow
```

### åŸºæœ¬ä½¿ç”¨

```python
from pose_transforms import build_train_pipeline, build_val_pipeline
import numpy as np

# é…ç½®ç¼–ç å™¨
codec = {
    'input_size': (192, 256),  # (W, H)
    'heatmap_size': (48, 64),  # (W, H)
    'sigma': 2.0
}

# COCO å·¦å³å¯¹ç§°å…³é”®ç‚¹å¯¹
flip_pairs = [
    (1, 2), (3, 4), (5, 6), (7, 8),
    (9, 10), (11, 12), (13, 14), (15, 16)
]

# æ„å»ºè®­ç»ƒpipeline
train_pipeline = build_train_pipeline(codec, flip_pairs)

# å‡†å¤‡è¾“å…¥æ•°æ®
results = {
    'img_path': 'path/to/image.jpg',
    'bbox': [100, 100, 200, 300],  # [x, y, w, h]
    'keypoints': np.random.rand(17, 2) * 100 + 100,  # 17ä¸ªå…³é”®ç‚¹
    'keypoints_visible': np.ones(17),
    'flip_pairs': flip_pairs
}

# æ‰§è¡Œpipeline
for transform in train_pipeline:
    results = transform(results)

# è·å–ç»“æœ
img_tensor = results['img']  # (3, H, W)
heatmaps = results['heatmaps']  # (num_keypoints, heatmap_h, heatmap_w)
```

### è‡ªå®šä¹‰Pipeline

```python
from pose_transforms import (
    LoadImage, GetBBoxCenterScale, RandomFlip,
    TopdownAffine, GenerateTarget, PackPoseInputs
)

# è‡ªå®šä¹‰pipeline
custom_pipeline = [
    LoadImage(to_float32=False),
    GetBBoxCenterScale(padding=1.5),
    RandomFlip(direction='horizontal', prob=0.5),
    TopdownAffine(input_size=(256, 256)),
    GenerateTarget(encoder=codec),
    PackPoseInputs()
]

# ä½¿ç”¨è‡ªå®šä¹‰pipeline
results = {'img_path': 'image.jpg', 'bbox': [0, 0, 100, 100]}
for transform in custom_pipeline:
    results = transform(results)
```

## ğŸ“Š æ•°æ®æ ¼å¼

### è¾“å…¥æ ¼å¼

```python
{
    'img_path': str,                    # å›¾åƒè·¯å¾„
    'bbox': [x, y, w, h],              # è¾¹ç•Œæ¡† [x, y, width, height]
    'keypoints': np.ndarray,            # (num_keypoints, 2 or 3)
    'keypoints_visible': np.ndarray,    # (num_keypoints,) 0æˆ–1
    'flip_pairs': List[Tuple[int, int]] # å·¦å³å¯¹ç§°å…³é”®ç‚¹å¯¹
}
```

### è¾“å‡ºæ ¼å¼

```python
{
    'img': torch.Tensor,                # (3, H, W) å½’ä¸€åŒ–åˆ°[0, 1]
    'heatmaps': torch.Tensor,           # (num_keypoints, heatmap_h, heatmap_w)
    'keypoint_weights': torch.Tensor,   # (num_keypoints,)
    'keypoints': torch.Tensor,          # (num_keypoints, 2 or 3)
    'data_sample': Dict                 # å…ƒä¿¡æ¯
}
```

## ğŸ¯ COCOæ ¼å¼ç¤ºä¾‹

COCOæ•°æ®é›†æœ‰17ä¸ªå…³é”®ç‚¹ï¼Œç´¢å¼•å¦‚ä¸‹ï¼š

```python
# COCO 17ä¸ªå…³é”®ç‚¹
keypoint_names = [
    'nose',           # 0
    'left_eye',       # 1
    'right_eye',      # 2
    'left_ear',       # 3
    'right_ear',      # 4
    'left_shoulder',  # 5
    'right_shoulder', # 6
    'left_elbow',     # 7
    'right_elbow',    # 8
    'left_wrist',     # 9
    'right_wrist',    # 10
    'left_hip',       # 11
    'right_hip',      # 12
    'left_knee',      # 13
    'right_knee',     # 14
    'left_ankle',     # 15
    'right_ankle'     # 16
]

# å·¦å³å¯¹ç§°å…³é”®ç‚¹å¯¹
flip_pairs = [
    (1, 2),   # å·¦çœ¼ <-> å³çœ¼
    (3, 4),   # å·¦è€³ <-> å³è€³
    (5, 6),   # å·¦è‚© <-> å³è‚©
    (7, 8),   # å·¦è‚˜ <-> å³è‚˜
    (9, 10),  # å·¦è…• <-> å³è…•
    (11, 12), # å·¦è‡€ <-> å³è‡€
    (13, 14), # å·¦è† <-> å³è†
    (15, 16)  # å·¦è¸ <-> å³è¸
]

# ä¸ŠåŠèº«å…³é”®ç‚¹ç´¢å¼•
upper_body_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

# ä¸‹åŠèº«å…³é”®ç‚¹ç´¢å¼•
lower_body_ids = [11, 12, 13, 14, 15, 16]
```

## ğŸ”§ å‚æ•°é…ç½®

### RandomFlip

```python
RandomFlip(
    direction='horizontal',  # 'horizontal' æˆ– 'vertical'
    prob=0.5                # ç¿»è½¬æ¦‚ç‡
)
```

### RandomHalfBody

```python
RandomHalfBody(
    min_total_keypoints=8,    # æœ€å°æ€»å…³é”®ç‚¹æ•°
    min_half_keypoints=2,     # æœ€å°åŠèº«å…³é”®ç‚¹æ•°
    prob=0.3,                 # è§¦å‘æ¦‚ç‡
    upper_body_ids=[0,1,...], # ä¸ŠåŠèº«å…³é”®ç‚¹ç´¢å¼•
    lower_body_ids=[11,12,...]# ä¸‹åŠèº«å…³é”®ç‚¹ç´¢å¼•
)
```

### RandomBBoxTransform

```python
RandomBBoxTransform(
    scale_factor=(0.75, 1.5), # ç¼©æ”¾èŒƒå›´
    shift_factor=0.16,         # å¹³ç§»å› å­
    rotate_factor=40,          # æ—‹è½¬è§’åº¦èŒƒå›´ [-40, 40]
    prob=1.0                   # è§¦å‘æ¦‚ç‡
)
```

### TopdownAffine

```python
TopdownAffine(
    input_size=(192, 256)  # è¾“å‡ºå°ºå¯¸ (W, H)
)
```

### GenerateTarget

```python
codec = {
    'input_size': (192, 256),   # è¾“å…¥å›¾åƒå°ºå¯¸ (W, H)
    'heatmap_size': (48, 64),   # çƒ­å›¾å°ºå¯¸ (W, H)
    'sigma': 2.0                # é«˜æ–¯æ ¸æ ‡å‡†å·®
}
GenerateTarget(encoder=codec)
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶ï¼š

```bash
python test_transforms.py
```

æµ‹è¯•åŒ…æ‹¬ï¼š
- âœ… å•ä¸ªtransformåŠŸèƒ½æµ‹è¯•
- âœ… å®Œæ•´pipelineæµ‹è¯•
- âœ… è®­ç»ƒå’ŒéªŒè¯pipelineæµ‹è¯•
- âœ… çƒ­å›¾ç”Ÿæˆå¯è§†åŒ–
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•

## ğŸ“ˆ æ€§èƒ½

åœ¨æ ‡å‡†é…ç½®ä¸‹ï¼ˆinput_size=192x256, 17ä¸ªå…³é”®ç‚¹ï¼‰ï¼š
- å•ä¸ªæ ·æœ¬å¤„ç†æ—¶é—´: ~10-20ms
- ååé‡: ~50-100 samples/secï¼ˆå•çº¿ç¨‹CPUï¼‰

## ğŸ” æ³¨æ„äº‹é¡¹

1. **åæ ‡ç³»ç»Ÿ**
   - æ‰€æœ‰åæ ‡ä½¿ç”¨(x, y)æ ¼å¼
   - å›¾åƒå°ºå¯¸ä½¿ç”¨(H, W)æ ¼å¼
   - è¾“å…¥è¾“å‡ºå°ºå¯¸ä½¿ç”¨(W, H)æ ¼å¼

2. **å…³é”®ç‚¹å¯è§æ€§**
   - 0: ä¸å¯è§
   - 1: è¢«é®æŒ¡ä½†æ ‡æ³¨
   - 2: å¯è§

3. **BBoxæ ¼å¼**
   - æ”¯æŒ[x, y, w, h]æ ¼å¼
   - æ”¯æŒ[x1, y1, x2, y2]æ ¼å¼ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰

4. **çƒ­å›¾ç”Ÿæˆ**
   - ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒ
   - è‡ªåŠ¨å¤„ç†è¾¹ç•Œæƒ…å†µ
   - æ”¯æŒå…³é”®ç‚¹æƒé‡

| ç‰¹æ€§ | æœ¬å®ç° | 
|------|--------|
| ä¾èµ– | torch, numpy, cv2 |
| é…ç½® | Pythonå­—å…¸ | 
| æ‰©å±•æ€§ | ç®€å•ç›´æ¥ | 
| æ€§èƒ½ | ç›¸è¿‘ | 

## ğŸ“ ç¤ºä¾‹é¡¹ç›®ç»“æ„

```
project/
â”œâ”€â”€ pose_transforms.py      # æ ¸å¿ƒtransformså®ç°
â”œâ”€â”€ test_transforms.py      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ README.md              # æœ¬æ–‡æ¡£
â””â”€â”€ your_training.py       # ä½ çš„è®­ç»ƒä»£ç 
```

## ğŸ’¡ æ‰©å±•å»ºè®®

1. **æ·»åŠ æ–°çš„æ•°æ®å¢å¼º**
   ```python
   class CustomTransform:
       def __init__(self, param1, param2):
           self.param1 = param1
           self.param2 = param2
       
       def __call__(self, results: Dict) -> Dict:
           # å®ç°ä½ çš„å¢å¼ºé€»è¾‘
           return results
   ```

2. **é›†æˆåˆ°è®­ç»ƒå¾ªç¯**
   ```python
   from torch.utils.data import Dataset, DataLoader
   
   class PoseDataset(Dataset):
       def __init__(self, data_list, pipeline):
           self.data_list = data_list
           self.pipeline = pipeline
       
       def __getitem__(self, idx):
           data_info = self.data_list[idx]
           results = {'img_path': data_info['img_path'], ...}
           
           for transform in self.pipeline:
               results = transform(results)
           
           return results['img'], results['heatmaps']
   ```

## ğŸ› å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆçƒ­å›¾å…¨æ˜¯0?**
A: æ£€æŸ¥å…³é”®ç‚¹åæ ‡æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…ï¼Œä»¥åŠkeypoints_visibleæ˜¯å¦æ­£ç¡®è®¾ç½®ã€‚

**Q: ç¿»è½¬åå…³é”®ç‚¹ä½ç½®ä¸å¯¹?**
A: ç¡®ä¿æä¾›äº†æ­£ç¡®çš„flip_pairså‚æ•°ã€‚

**Q: å†…å­˜å ç”¨è¿‡é«˜?**
A: å‡å°batch_sizeæˆ–é™ä½çƒ­å›¾åˆ†è¾¨ç‡ã€‚

## ğŸ“„ è®¸å¯

MIT License

## ğŸ™ è‡´è°¢

