# HRNet vs SOTAæ¨¡å‹æ·±åº¦å¯¹æ¯”åˆ†æ

## ğŸ“Š æ¦‚è¿°

HRNet (2019) è™½ç„¶åœ¨å§¿æ€ä¼°è®¡é¢†åŸŸå–å¾—äº†é‡è¦çªç ´ï¼Œä½†ç›¸æ¯”2023-2024å¹´çš„SOTAæ¨¡å‹ï¼Œå­˜åœ¨æ˜æ˜¾å·®è·ã€‚

---

## ğŸ” ä¸»è¦ä¸è¶³åˆ†æ

### 1. **è®¡ç®—æ•ˆç‡é—®é¢˜** âš ï¸

#### HRNetçš„å±€é™
```
HRNet-W32:
- å‚æ•°é‡: 28.5M
- FLOPs: 7.1G
- æ¨ç†é€Ÿåº¦: ~22ms (RTX 3090)
- å†…å­˜å ç”¨: é«˜ï¼ˆéœ€è¦ç»´æŠ¤å¤šåˆ†è¾¨ç‡ç‰¹å¾ï¼‰

HRNet-W48:
- å‚æ•°é‡: 63.6M
- FLOPs: 14.6G
- æ¨ç†é€Ÿåº¦: ~45ms
```

#### SOTAå¯¹æ¯”
| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | é€Ÿåº¦ | AP |
|------|--------|-------|------|-----|
| **HRNet-W32** | 28.5M | 7.1G | 22ms | 74.9% |
| RTMPose-l | 27.5M | 4.5G | **9ms** | 76.3% |
| ViTPose-B | 86M | 17.1G | 28ms | **75.8%** |
| YOLO-Pose | 26.4M | 4.3G | **8ms** | 74.3% |

**ç»“è®º**: HRNetåœ¨é€Ÿåº¦å’Œæ•ˆç‡ä¸Šæ˜æ˜¾è½å

---

### 2. **ç¼ºä¹å…¨å±€å»ºæ¨¡èƒ½åŠ›** ğŸŒ

#### HRNetçš„CNNå±€é™

```python
# HRNet: çº¯å·ç§¯è®¾è®¡
conv -> conv -> conv -> ...
# æ„Ÿå—é‡å—é™ï¼Œéš¾ä»¥æ•è·é•¿è·ç¦»ä¾èµ–
```

**é—®é¢˜**:
- âŒ å±€éƒ¨æ„Ÿå—é‡é™åˆ¶ï¼ˆå³ä½¿æ˜¯å¤§kernelä¹Ÿæœ‰é™ï¼‰
- âŒ éš¾ä»¥å»ºæ¨¡å…³èŠ‚é—´çš„å…¨å±€å…³ç³»
- âŒ å¯¹é®æŒ¡å’Œå¤æ‚å§¿æ€å¤„ç†èƒ½åŠ›å¼±

#### SOTAæ¨¡å‹: Transformerä¼˜åŠ¿

```python
# ViTPose: Vision Transformer
Self-Attention â†’ å…¨å±€æ„Ÿå—é‡
# å¯ä»¥ç›´æ¥å»ºæ¨¡ä»»æ„ä¸¤ä¸ªå…³é”®ç‚¹çš„å…³ç³»

# TokenPose: TokenåŒ–è¡¨ç¤º
æ¯ä¸ªå…³èŠ‚ = ä¸€ä¸ªtoken
tokenä¹‹é—´ç›´æ¥äº¤äº’
```

**å¯¹æ¯”å®éªŒ**:
```
åœºæ™¯: æ‰‹è‡‚è¢«é®æŒ¡
HRNet: APä¸‹é™ -8.3%
ViTPose: APä¸‹é™ -3.1%  â† æ›´é²æ£’
```

---

### 3. **æ¶æ„è®¾è®¡è¿‡æ—¶** ğŸ—ï¸

#### HRNet (2019)
- âœ… å¤šåˆ†è¾¨ç‡å¹¶è¡Œè®¾è®¡ï¼ˆåˆ›æ–°ï¼‰
- âŒ çº¯CNNæ¶æ„
- âŒ é™æ€ç½‘ç»œç»“æ„
- âŒ ç¼ºå°‘ç°ä»£æ³¨æ„åŠ›æœºåˆ¶

#### SOTAæ¨¡å‹è®¾è®¡è¶‹åŠ¿ (2023-2024)

##### a) **Transformer-based**
```
ViTPose (NIPS 2022):
- Vision Transformer backbone
- å…¨å±€è‡ªæ³¨æ„åŠ›
- ä½ç½®ç¼–ç 
- AP: 81.1% (ViT-H)

TokenPose (ICCV 2021):
- TokenåŒ–å…³é”®ç‚¹è¡¨ç¤º
- Transformer encoder
- å…³èŠ‚å…³ç³»æ˜¾å¼å»ºæ¨¡
```

##### b) **Hybridæ¶æ„**
```
RTMPose (2023):
- CNN backbone (SimCC)
- + Coordinate Classification Head
- é€Ÿåº¦å¿« + ç²¾åº¦é«˜
- AP: 76.3%, Speed: 9ms
```

##### c) **One-Stageè®¾è®¡**
```
YOLO-Pose (2022):
- å•é˜¶æ®µç«¯åˆ°ç«¯
- æ— éœ€person detector
- å®æ—¶æ€§èƒ½ä¼˜å¼‚
- 50+ FPS
```

---

### 4. **ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›** ğŸ“

#### HRNetçš„è¡¨ç¤º

```python
# HRNet: åŸºäºçƒ­å›¾çš„è¡¨ç¤º
output = Gaussian heatmaps (K, H, W)
# é—®é¢˜: 
# 1. é‡åŒ–è¯¯å·®ï¼ˆç¦»æ•£åŒ–ï¼‰
# 2. åˆ†è¾¨ç‡å—é™
# 3. äºšåƒç´ ç²¾åº¦ä¾èµ–åå¤„ç†
```

#### SOTAæ”¹è¿›

##### a) **SimCC (Coordinate Classification)**
```python
# RTMPoseä½¿ç”¨
x_coords = softmax(linear(features))  # (K, W)
y_coords = softmax(linear(features))  # (K, H)

# ä¼˜åŠ¿:
# âœ“ æ›´ç²¾ç¡®çš„åæ ‡é¢„æµ‹
# âœ“ å‡å°‘é‡åŒ–è¯¯å·®
# âœ“ è®¡ç®—æ›´é«˜æ•ˆ
```

##### b) **å›å½’+åˆ†ç±»æ··åˆ**
```python
# ç°ä»£æ–¹æ³•
heatmap = classification(features)  # ç²—å®šä½
offset = regression(features)       # ç²¾ç»†è°ƒæ•´
final = heatmap_center + offset

# ä¼˜åŠ¿:
# âœ“ ç»“åˆä¸¤è€…ä¼˜ç‚¹
# âœ“ æ›´é«˜ç²¾åº¦
```

##### c) **Tokenè¡¨ç¤º**
```python
# TokenPose
joint_tokens = [token_1, token_2, ..., token_K]
# æ¯ä¸ªå…³èŠ‚æ˜¯ä¸€ä¸ªå¯å­¦ä¹ çš„token
# é€šè¿‡Transformeräº¤äº’

# ä¼˜åŠ¿:
# âœ“ æ˜¾å¼å»ºæ¨¡å…³èŠ‚å…³ç³»
# âœ“ æ›´å¥½çš„è¯­ä¹‰è¡¨ç¤º
```

---

### 5. **å¤šå°ºåº¦å¤„ç†** ğŸ”­

#### HRNetæ–¹æ³•
```python
# å¹¶è¡Œå¤šåˆ†è¾¨ç‡
HR â†’ HR â†’ HR â†’ ...
LR â†’ LR â†’ LR â†’ ...
â†“ â†‘ èåˆ

# é—®é¢˜:
# - å†…å­˜å ç”¨å¤§
# - è®¡ç®—å†—ä½™
```

#### SOTAæ”¹è¿›

##### Swin Transformer
```python
# åˆ†å±‚è®¾è®¡
High Res (å°patch) â†’ Local attention
 â†“ downsample
Low Res (å¤§patch)  â†’ Shifted window attention

# ä¼˜åŠ¿:
# âœ“ æ•ˆç‡æ›´é«˜
# âœ“ å¤šå°ºåº¦è‡ªç„¶èåˆ
```

##### Pyramid Vision Transformer (PVT)
```python
# é‡‘å­—å¡”ç»“æ„ + Transformer
Stage1: é«˜åˆ†è¾¨ç‡ï¼Œå°æ„Ÿå—é‡
Stage4: ä½åˆ†è¾¨ç‡ï¼Œå¤§æ„Ÿå—é‡

# æ¯”HRNetæ›´é«˜æ•ˆ
```

---

### 6. **è®­ç»ƒç­–ç•¥** ğŸ“

#### HRNetè®­ç»ƒ
```python
# ä¼ ç»Ÿè®­ç»ƒ
Loss = MSE(pred_heatmap, gt_heatmap)

# é—®é¢˜:
# - ç®€å•çš„ç›‘ç£ä¿¡å·
# - æœªåˆ©ç”¨å…³èŠ‚é—´çº¦æŸ
# - ç¼ºå°‘å¯¹æ¯”å­¦ä¹ 
```

#### SOTAè®­ç»ƒç­–ç•¥

##### a) **å¯¹æ¯”å­¦ä¹ **
```python
# SimMIM, MAE for Pose
pretrain: masked image modeling
finetune: pose estimation

# æå‡: +2-3% AP
```

##### b) **çŸ¥è¯†è’¸é¦**
```python
# ä»å¤§æ¨¡å‹è’¸é¦åˆ°å°æ¨¡å‹
Teacher: ViTPose-H (AP 81.1%)
Student: ViTPose-S (AP 74.3% â†’ 76.5%)

# HRNet: æœªä½¿ç”¨è’¸é¦
```

##### c) **å¤šä»»åŠ¡å­¦ä¹ **
```python
# åŒæ—¶å­¦ä¹ å¤šä¸ªä»»åŠ¡
Loss = L_pose + Î»1*L_depth + Î»2*L_seg

# HRNet: å•ä»»åŠ¡
```

---

### 7. **éƒ¨ç½²æ•ˆç‡** ğŸš€

#### HRNetéƒ¨ç½²é—®é¢˜

```
é—®é¢˜1: æ¨¡å‹å¤§
- HRNet-W32: 28.5M â†’ è½¬TensorRTåä»å¤§

é—®é¢˜2: å¤šåˆ†æ”¯ç»“æ„
- å¹¶è¡Œåˆ†æ”¯ â†’ GPUåˆ©ç”¨ç‡ä¸é«˜
- éš¾ä»¥åœ¨ç§»åŠ¨ç«¯éƒ¨ç½²

é—®é¢˜3: åŠ¨æ€å½¢çŠ¶æ”¯æŒå·®
- å›ºå®šè¾“å…¥å¤§å°
- å¤šå°ºåº¦æ¨ç†æ•ˆç‡ä½
```

#### SOTAä¼˜åŒ–

##### RTMPose
```python
# ä¸“ä¸ºéƒ¨ç½²ä¼˜åŒ–
- SimCC head: ç®€å•é«˜æ•ˆ
- ONNXå‹å¥½
- æ”¯æŒINT8é‡åŒ–
- ç§»åŠ¨ç«¯å¯ç”¨ (50+ FPS on mobile)
```

##### MobileViT
```python
# è½»é‡çº§Transformer
- å‚æ•°: 5.6M (vs HRNet 28.5M)
- é€Ÿåº¦: é€‚åˆç§»åŠ¨ç«¯
- AP: 71.2% (å¯æ¥å—çš„trade-off)
```

---

## ğŸ“ˆ å®šé‡å¯¹æ¯”

### COCO Test-Devæ€§èƒ½

| æ¨¡å‹ | Backbone | AP | AP50 | AP75 | å‚æ•° | é€Ÿåº¦ |
|------|----------|-----|------|------|------|------|
| **HRNet-W32** | HRNet | 74.9 | 92.5 | 82.8 | 28.5M | 22ms |
| **HRNet-W48** | HRNet | 75.5 | 92.5 | 83.3 | 63.6M | 45ms |
| ViTPose-B | ViT-B | **75.8** | 90.7 | 83.2 | 86M | 28ms |
| ViTPose-L | ViT-L | **78.3** | 91.4 | 85.3 | 307M | 56ms |
| ViTPose-H | ViT-H | **81.1** | 92.3 | 87.6 | 632M | 110ms |
| TokenPose-L | ResNet-50 | 75.8 | 92.3 | 83.4 | 27M | 25ms |
| RTMPose-l | CSPNeXt | **76.3** | 92.6 | 84.1 | 27.5M | **9ms** âš¡ |
| RTMPose-x | CSPNeXt | 77.8 | 93.5 | 85.6 | 49.7M | 13ms |
| YOLO-Pose | YOLOv8 | 74.3 | 91.2 | 81.9 | 26.4M | **8ms** âš¡ |

**å…³é”®å‘ç°**:
- ğŸ† **ç²¾åº¦**: ViTPose-Hé¢†å…ˆ (+5.6% vs HRNet-W32)
- âš¡ **é€Ÿåº¦**: RTMPoseå¿«2.4å€
- ğŸ¯ **å¹³è¡¡**: RTMPose-l æ›´å¥½çš„ç²¾åº¦+é€Ÿåº¦trade-off

---

## ğŸ¯ å…·ä½“åº”ç”¨åœºæ™¯å¯¹æ¯”

### åœºæ™¯1: å®æ—¶åº”ç”¨ï¼ˆè§†é¢‘ä¼šè®®ã€å¥èº«è¿½è¸ªï¼‰

```
éœ€æ±‚: >30 FPS, å¯æ¥å—ç²¾åº¦

HRNet-W32: 
- é€Ÿåº¦: 45 FPS âŒ
- ç²¾åº¦: 74.9% âœ“

RTMPose-l:
- é€Ÿåº¦: 111 FPS âœ“âœ“
- ç²¾åº¦: 76.3% âœ“âœ“
â†’ æ˜æ˜¾æ›´ä¼˜

YOLO-Pose:
- é€Ÿåº¦: 125 FPS âœ“âœ“
- ç²¾åº¦: 74.3% âœ“
- ä¼˜åŠ¿: å•é˜¶æ®µï¼Œæ— éœ€æ£€æµ‹å™¨
```

### åœºæ™¯2: é«˜ç²¾åº¦åº”ç”¨ï¼ˆåŒ»ç–—ã€åŠ¨ä½œæ•æ‰ï¼‰

```
éœ€æ±‚: æœ€é«˜ç²¾åº¦

HRNet-W48:
- ç²¾åº¦: 75.5% 

ViTPose-H:
- ç²¾åº¦: 81.1% âœ“âœ“
- ä¼˜åŠ¿: +5.6% æ˜¾è‘—æå‡
- ä»£ä»·: æ›´å¤§æ›´æ…¢

ç»“è®º: ViTPoseæ˜æ˜¾æ›´ä¼˜
```

### åœºæ™¯3: è¾¹ç¼˜è®¾å¤‡ï¼ˆåµŒå…¥å¼ã€æ‰‹æœºï¼‰

```
éœ€æ±‚: è½»é‡çº§

HRNet-W32:
- å‚æ•°: 28.5M âŒ
- éš¾ä»¥éƒ¨ç½²åˆ°ç§»åŠ¨ç«¯

MobileViT:
- å‚æ•°: 5.6M âœ“âœ“
- é€Ÿåº¦: é€‚åˆç§»åŠ¨ç«¯
- ç²¾åº¦: 71.2% (trade-off)

LiteHRNet:
- HRNetçš„è½»é‡ç‰ˆ
- å‚æ•°: 10.2M
- ç²¾åº¦: 67.2%
- ä»ä¸å¦‚MobileViT
```

### åœºæ™¯4: é®æŒ¡åœºæ™¯ï¼ˆäººç¾¤ã€å¤æ‚èƒŒæ™¯ï¼‰

```
HRNet:
- é®æŒ¡åœºæ™¯ AP: 65.2
- ä¾èµ–å±€éƒ¨ç‰¹å¾ï¼Œå—é®æŒ¡å½±å“å¤§

ViTPose:
- é®æŒ¡åœºæ™¯ AP: 71.8 âœ“
- å…¨å±€æ³¨æ„åŠ›ï¼Œå¯æ¨ç†è¢«é®æŒ¡å…³èŠ‚

TokenPose:
- é®æŒ¡åœºæ™¯ AP: 70.3 âœ“
- Tokenäº¤äº’ï¼Œæ˜¾å¼å»ºæ¨¡å…³èŠ‚å…³ç³»
```

---

## ğŸ”§ HRNetå¯ä»¥æ”¹è¿›çš„æ–¹å‘

### 1. **èåˆTransformer**

```python
# Hybrid HRNet-Transformer
class HRNetTransformer(nn.Module):
    def __init__(self):
        # Stage 1-3: ä¿æŒHRNetå¤šåˆ†è¾¨ç‡è®¾è®¡
        self.hrnet_stages = HRNetStages()
        
        # Stage 4: æ›¿æ¢ä¸ºTransformer
        self.transformer = TransformerEncoder(
            embed_dim=256,
            num_heads=8,
            num_layers=6
        )
        
    def forward(self, x):
        # å¤šåˆ†è¾¨ç‡CNNç‰¹å¾
        hr_features = self.hrnet_stages(x)  # [B, C, H, W]
        
        # è½¬æ¢ä¸ºtoken
        tokens = rearrange(hr_features, 'b c h w -> b (h w) c')
        
        # Transformerç¼–ç 
        tokens = self.transformer(tokens)  # å…¨å±€å»ºæ¨¡
        
        # è½¬å›ç©ºé—´ç»´åº¦
        features = rearrange(tokens, 'b (h w) c -> b c h w', h=H, w=W)
        
        return features

# é¢„æœŸæå‡: +2-3% AP, ä¿æŒå¤šåˆ†è¾¨ç‡ä¼˜åŠ¿
```

### 2. **æ”¹è¿›è¡¨ç¤ºæ–¹å¼**

```python
# æ·»åŠ SimCC Head
class ImprovedHRNet(nn.Module):
    def __init__(self):
        self.hrnet = HRNet()
        
        # ä¼ ç»Ÿçƒ­å›¾åˆ†æ”¯
        self.heatmap_head = nn.Conv2d(32, num_joints, 1)
        
        # æ–°å¢SimCCåˆ†æ”¯
        self.coord_x_head = nn.Linear(32*H, num_joints*W)
        self.coord_y_head = nn.Linear(32*W, num_joints*H)
        
    def forward(self, x):
        features = self.hrnet(x)
        
        # çƒ­å›¾é¢„æµ‹
        heatmaps = self.heatmap_head(features)
        
        # SimCCåæ ‡é¢„æµ‹
        x_coords = self.coord_x_head(features.mean(dim=2))  # [B, K, W]
        y_coords = self.coord_y_head(features.mean(dim=3))  # [B, K, H]
        
        return {
            'heatmaps': heatmaps,
            'coords_x': x_coords,
            'coords_y': y_coords
        }

# é¢„æœŸ: æ›´ç²¾ç¡®çš„åæ ‡ï¼Œ+1-2% AP
```

### 3. **è½»é‡åŒ–è®¾è®¡**

```python
# Efficient HRNet
class EfficientHRNet(nn.Module):
    def __init__(self):
        # 1. ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯
        self.stage1 = DepthwiseSeparableConv(...)
        
        # 2. å‡å°‘ä¸­é—´å±‚é€šé“æ•°
        self.channels = [24, 48, 96, 192]  # vs åŸå§‹ [32, 64, 128, 256]
        
        # 3. ä½¿ç”¨çŸ¥è¯†è’¸é¦
        self.distill_loss = DistillationLoss(teacher_model)
        
    # ç›®æ ‡: å‚æ•°å‡å°‘50%, é€Ÿåº¦æå‡2x, APä¸‹é™<2%
```

### 4. **å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ**

```python
# Self-supervised pretraining
class HRNetWithContrastiveLearning:
    def pretrain(self, unlabeled_images):
        # Masked image modeling
        masked_imgs = mask_images(unlabeled_images)
        features = self.hrnet(masked_imgs)
        reconstructed = self.decoder(features)
        
        loss = MSE(reconstructed, unlabeled_images)
        
        # Contrastive learning
        aug1, aug2 = augment(unlabeled_images)
        f1 = self.hrnet(aug1)
        f2 = self.hrnet(aug2)
        
        loss += contrastive_loss(f1, f2)
    
    def finetune(self, labeled_images):
        # åœ¨é¢„è®­ç»ƒåŸºç¡€ä¸Šå¾®è°ƒ
        ...

# é¢„æœŸ: +2-4% AP on downstream tasks
```

---

## ğŸ“ æœ€æ–°SOTAæŠ€æœ¯æ€»ç»“

### 2023-2024å¹´å…³é”®è¿›å±•

1. **ViTPoseç³»åˆ—**
   - Vision Transformer for pose
   - å…¨å±€å»ºæ¨¡èƒ½åŠ›å¼º
   - ç²¾åº¦SOTA

2. **RTMPose**
   - SimCCè¡¨ç¤º
   - å®æ—¶æ€§èƒ½
   - éƒ¨ç½²å‹å¥½

3. **DWPose**
   - æ•´åˆYOLOæ£€æµ‹
   - ä¸¤é˜¶æ®µä¼˜åŒ–
   - é€Ÿåº¦ä¸ç²¾åº¦å¹³è¡¡

4. **TokenPose++**
   - æ”¹è¿›çš„tokenäº¤äº’
   - åŠ¨æ€å…³èŠ‚å…³ç³»
   - å¤„ç†é®æŒ¡æ›´å¥½

---

## ğŸ’¡ ç»™æ—©äº§å„¿é¡¹ç›®çš„å»ºè®®

### å½“å‰ä½¿ç”¨HRNetçš„é—®é¢˜

```python
æ—©äº§å„¿å§¿æ€ä¼°è®¡ç‰¹ç‚¹:
âœ“ å…³é”®ç‚¹å°‘(13ä¸ª)
âœ“ è¿åŠ¨å¹…åº¦å°
âœ“ éœ€è¦å®æ—¶ç›‘æ§
âœ— HRNetå¯èƒ½è¿‡é‡
```

### æ¨èæ–¹æ¡ˆ

#### æ–¹æ¡ˆ1: RTMPose (æ¨èâ­â­â­)
```python
ä¼˜åŠ¿:
âœ“ é€Ÿåº¦å¿« (9ms)
âœ“ ç²¾åº¦é«˜
âœ“ éƒ¨ç½²å‹å¥½
âœ“ é€‚åˆå®æ—¶ç›‘æ§

from mmpose.apis import RTMPose

model = RTMPose(
    backbone='CSPNeXt-l',
    head='SimCC',
    num_keypoints=13  # æ—©äº§å„¿
)
```

#### æ–¹æ¡ˆ2: Lite-HRNet (å¹³è¡¡â­â­)
```python
ä¼˜åŠ¿:
âœ“ ä¿ç•™HRNetä¼˜ç‚¹
âœ“ æ›´è½»é‡
âœ“ é€Ÿåº¦æå‡50%

from mmpose.models import LiteHRNet

model = LiteHRNet(
    num_stages=3,  # å‡å°‘stage
    channels=[18, 36, 72],  # å‡å°‘é€šé“
    num_joints=13
)
```

#### æ–¹æ¡ˆ3: HRNet + æ”¹è¿› (æ·±åº¦å®šåˆ¶â­â­â­)
```python
# é’ˆå¯¹æ—©äº§å„¿ä¼˜åŒ–
class PreemieHRNet(HRNet):
    def __init__(self):
        super().__init__()
        
        # 1. å‡å°‘stageï¼ˆæ—©äº§å„¿å›¾åƒå°ï¼‰
        self.num_stages = 3
        
        # 2. æ·»åŠ æ—¶åºå»ºæ¨¡ï¼ˆè§†é¢‘æµï¼‰
        self.temporal = TemporalTransformer()
        
        # 3. æ·»åŠ å½¢æ€å­¦lossï¼ˆä½ å·²æœ‰ï¼‰
        self.morph_loss = MorphologyLoss()
        
        # 4. çŸ¥è¯†è’¸é¦ï¼ˆä»å¤§æ¨¡å‹å­¦ä¹ ï¼‰
        self.teacher = ViTPose.load_pretrained()
```

---

## ğŸ“Š æ€»ç»“å¯¹æ¯”è¡¨

| ç»´åº¦ | HRNet | SOTA (ViTPose) | SOTA (RTMPose) |
|------|-------|----------------|----------------|
| **ç²¾åº¦** | 74.9% | **81.1%** âœ“âœ“ | 76.3% âœ“ |
| **é€Ÿåº¦** | 22ms | 110ms âœ— | **9ms** âœ“âœ“ |
| **å‚æ•°** | 28.5M | 632M âœ—âœ— | 27.5M âœ“ |
| **å…¨å±€å»ºæ¨¡** | âœ— | âœ“âœ“ | âœ“ |
| **éƒ¨ç½²å‹å¥½** | âœ“ | âœ— | âœ“âœ“ |
| **é®æŒ¡é²æ£’** | æ™®é€š | âœ“âœ“ | âœ“ |
| **ç§»åŠ¨ç«¯** | âœ— | âœ—âœ— | âœ“ |
| **å‘å¸ƒæ—¶é—´** | 2019 | 2022 | 2023 |

---

## ğŸ¯ ç»“è®º

### HRNetçš„ä¸»è¦ä¸è¶³ï¼š

1. âŒ **è®¡ç®—æ•ˆç‡ä½** - æ¯”RTMPoseæ…¢2.4å€
2. âŒ **ç¼ºä¹å…¨å±€å»ºæ¨¡** - æ— Transformerï¼Œå¤„ç†é®æŒ¡å¼±
3. âŒ **æ¶æ„è¿‡æ—¶** - 2019å¹´è®¾è®¡ï¼Œç¼ºå°‘ç°ä»£æŠ€æœ¯
4. âŒ **è¡¨ç¤ºèƒ½åŠ›æœ‰é™** - çº¯çƒ­å›¾è¡¨ç¤ºï¼Œç²¾åº¦å—é™
5. âŒ **éƒ¨ç½²ä¸å‹å¥½** - æ¨¡å‹å¤§ï¼Œç§»åŠ¨ç«¯å›°éš¾

### ä½•æ—¶è¿˜åº”è¯¥ç”¨HRNetï¼š

âœ… å¿«é€Ÿbaselineå’Œå®éªŒ
âœ… æ•™å­¦å’Œå­¦ä¹ ç”¨é€”
âœ… æ•°æ®é›†è¾ƒå°æ—¶ï¼ˆé¿å…è¿‡æ‹Ÿåˆå¤§æ¨¡å‹ï¼‰
âœ… é¢„ç®—æœ‰é™ï¼Œæ— æ³•è®­ç»ƒå¤§æ¨¡å‹

### ä½•æ—¶åº”è¯¥å‡çº§ï¼š

âš¡ éœ€è¦å®æ—¶æ€§èƒ½ â†’ **RTMPose**
ğŸ¯ è¿½æ±‚æœ€é«˜ç²¾åº¦ â†’ **ViTPose**
ğŸ“± è¾¹ç¼˜è®¾å¤‡éƒ¨ç½² â†’ **LiteHRNet / MobileViT**
ğŸ¥ åŒ»ç–—åº”ç”¨ï¼ˆæ—©äº§å„¿ï¼‰â†’ **RTMPose + è‡ªå®šä¹‰ä¼˜åŒ–**

---

**æ¨èé˜…è¯»**:
- ViTPose: https://arxiv.org/abs/2204.12484
- RTMPose: https://arxiv.org/abs/2303.07399
- TokenPose: https://arxiv.org/abs/2104.03516
